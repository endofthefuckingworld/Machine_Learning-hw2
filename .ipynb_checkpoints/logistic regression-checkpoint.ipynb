{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "np.random.seed(0)\n",
    "X_train_fpath = 'C:/Users/Terry/Machine_Learning-hw2/X_train'\n",
    "Y_train_fpath = 'C:/Users/Terry/Machine_Learning-hw2/Y_train'\n",
    "X_test_fpath = 'C:/Users/Terry/Machine_Learning-hw2/X_test'\n",
    "\n",
    "\n",
    "# Parse csv files to numpy array\n",
    "with open(X_train_fpath) as f:\n",
    "    next(f)\n",
    "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
    "with open(Y_train_fpath) as f:\n",
    "    next(f)\n",
    "    Y_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
    "with open(X_test_fpath) as f:\n",
    "    next(f)\n",
    "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將training data再拆成training set,valid set\n",
    "#在此就不做feature scaling，因為感覺有太多類別資料\n",
    "X_train_set=X_train[:math.floor(0.1*np.shape(X_train)[0]),:]\n",
    "Y_train=Y_train[:math.floor(0.1*np.shape(X_train)[0]),:]\n",
    "X_valid_set=X_train[math.floor(0.85*np.shape(X_train)[0]):,:]\n",
    "print(np.shape(X_valid_set),np.shape(X_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic function\n",
    "#所有超過10^-8或1-10^-8之機率都會強制變成該數值\n",
    "def logistic_function(z):\n",
    "    print(z)\n",
    "    for i in range(len(z)):\n",
    "        z[i]=np.clip(1 / (1.0 + np.exp(-z[i])), 1e-8, 1 - (1e-8))\n",
    "        \n",
    "    return z\n",
    "#共510個解釋變數加一個截距項\n",
    "parameter=np.shape(X_train_set)[1]+1\n",
    "#儲存所有參數值的array，先全部設0\n",
    "parameter_set=np.zeros([parameter,1])\n",
    "adagrad=np.zeros([parameter,1])\n",
    "regularization=np.empty([parameter, 1],dtype = float)\n",
    "learning_rate=10\n",
    "Lambda=0.5\n",
    "iter_time=1000\n",
    "\n",
    "X_set = np.concatenate((np.ones([np.shape(X_train_set)[0], 1]), X_train_set), axis=1).astype(float)\n",
    "\n",
    "for i in range(iter_time):\n",
    "        for k in range(parameter):\n",
    "            regularization[k][0]=2*Lambda*parameter_set[k][0]\n",
    "        Y_predict=logistic_function(np.dot(X_set, parameter_set))\n",
    "        gradient = (-1) * np.dot(X_set.transpose(),Y_train-Y_predict)+regularization \n",
    "        \n",
    "        if(i%100==0):\n",
    "            cross_entropy = -(np.dot(Y_train.transpose(), np.log(Y_predict)) + np.dot((1 - Y_train).transpose(), np.log(1 - Y_predict)))\n",
    "            acc = 1 - np.mean(np.abs(Y_predict - Y_train))\n",
    "            print(i,str(cross_entropy),acc)\n",
    "            \n",
    "        adagrad += gradient ** 2\n",
    "        parameter_set = parameter_set - learning_rate * gradient / np.sqrt(adagrad + 1e-8)\n",
    "np.save('weight.npy', parameter_set)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
