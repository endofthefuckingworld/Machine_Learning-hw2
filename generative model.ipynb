{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接依據我們對模型的假設，各個解釋變數間相互獨立，計算出模型參數\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "np.random.seed(0)\n",
    "\n",
    "X_train_fpath = 'C:/Users/Terry/Machine_Learning-hw2/X_train'\n",
    "Y_train_fpath = 'C:/Users/Terry/Machine_Learning-hw2/Y_train'\n",
    "X_test_fpath = 'C:/Users/Terry/Machine_Learning-hw2/X_test'\n",
    "\n",
    "\n",
    "# Parse csv files to numpy array\n",
    "with open(X_train_fpath) as f:\n",
    "    next(f)\n",
    "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = np.float64)\n",
    "with open(Y_train_fpath) as f:\n",
    "    next(f)\n",
    "    Y_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = np.float64)\n",
    "with open(X_test_fpath) as f:\n",
    "    next(f)\n",
    "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = np.float64)\n",
    "\n",
    "\n",
    "#feature scaling\n",
    "column = np.arange(X_train.shape[1])   #510個變數\n",
    "X_mean = np.mean(X_train[:, column] ,0).reshape(1, -1)\n",
    "X_std  = np.std(X_train[:, column], 0).reshape(1, -1)\n",
    "X_train[:,column] = (X_train[:, column] - X_mean) / (X_std + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先將資料分作兩群\n",
    "training_data= pd.DataFrame(np.concatenate((Y_train, X_train), axis=1).astype(np.float64))\n",
    "\n",
    "training_1=np.array(training_data[training_data[0]==1].iloc[:,1:])\n",
    "training_0=np.array(training_data[training_data[0]==0].iloc[:,1:])\n",
    "\n",
    "#計算平均\n",
    "mean_1=np.mean(training_1,axis=0)  #column平均\n",
    "mean_0=np.mean(training_0,axis=0)  \n",
    "\n",
    "#計算covariance\n",
    "cov_0=np.zeros([len(mean_0),len(mean_0)],dtype = np.float64)\n",
    "cov_1=np.zeros([len(mean_1),len(mean_1)],dtype = np.float64)\n",
    "\n",
    "#每一個變數和總共510個變數計算離均差平方和\n",
    "for x in training_0:\n",
    "    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / training_0.shape[0]\n",
    "for x in training_1:\n",
    "    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / training_1.shape[0]\n",
    "    \n",
    "#由於共變異數矩陣是兩個群體共用\n",
    "\n",
    "cov= (len(training_0)*cov_0+len(training_1)*cov_1)/((len(training_1)+len(training_0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(z):\n",
    "    \n",
    "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n",
    "\n",
    "def predict(x_set,Parameter_set):\n",
    "    \n",
    "    return np.dot(x_set, Parameter_set)\n",
    "\n",
    "def accuracy(Y_train,Y_predict):\n",
    "    cross_entropy = -1*(np.dot(Y_train.transpose(), np.log(Y_predict+1e-8)) + np.dot((1 - Y_train).transpose(), np.log(1 - Y_predict+1e-8)))\n",
    "    acc = 1 - np.mean(np.abs(Y_predict - Y_train))\n",
    "    \n",
    "    return cross_entropy,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.873820406959599\n",
      "cross_entropy: 126107.97989899815\n"
     ]
    }
   ],
   "source": [
    "u, s, v = np.linalg.svd(cov, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "\n",
    "\n",
    "# Directly compute weights and bias\n",
    "w = np.dot(inv,mean_0 - mean_1)\n",
    "b = (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\n",
    "    + np.log(float(training_0.shape[0]) / training_1.shape[0]) \n",
    "\n",
    "y_predict=1-np.round(logistic_function(np.dot(X_train,w)+b))\n",
    "Y_train=Y_train.reshape(len(y_predict),)\n",
    "cross_entropy,acc=accuracy(Y_train,y_predict)\n",
    "\n",
    "\n",
    "print('Training accuracy:', acc)\n",
    "print('cross_entropy:', cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
